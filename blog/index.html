<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> blog | ICLR Blogposts 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Home to the 2023 ICLR Blogposts track "/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/2023/assets/img/iclr_favicon.ico"/> <link rel="stylesheet" href="/2023/assets/css/main.css"> <link rel="canonical" href="https://iclr-blogposts.github.io/2023/blog/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/2023/assets/js/theme.js"></script> <script src="/2023/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2023/">ICLR Blogposts 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2023/about">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/2023/call">call for blogposts</a> </li> <li class="nav-item "> <a class="nav-link" href="/2023/submitting">submitting</a> </li> <li class="nav-item "> <a class="nav-link" href="/2023/reviewing">reviewing</a> </li> <li class="nav-item active"> <a class="nav-link" href="/2023/blog/index.html">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">other iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2023/"><strong>2023</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/" target="_blank" rel="noopener noreferrer">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="header-background"><div class="img"></div></div> <div class="container mt-5"> <div class="post"> <div class="header-bar"> <h1>blogposts</h1> <h2>Accepted Blog Posts</h2> </div> <ul class="post-list"> <li> <h3> <a class="post-title" href="/2023/blog/2023/hitchhikers-momentum/">A Hitchhiker's Guide to Momentum</a> </h3> <p>Polyak momentum is one of the most iconic methods in optimization. Despite it's simplicity, it features rich dynamics that depend both on the step-size and momentum parameter. In this blog post we identify the different regions of the parameter space and discuss their convergence properties using the theory of Chebyshev polynomials.</p> <p class="post-meta"> 19 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/autoregressive-neural-pde-solver/">Autoregressive Renaissance in Neural PDE Solvers</a> </h3> <p>Recent developments in the field of neural partial differential equation (PDE) solvers have placed a strong emphasis on neural operators. However, the paper Message Passing Neural PDE Solver by Brandstetter et al. published in ICLR 2022 revisits autoregressive models and designs a message passing graph neural network that is comparable with or outperforms both the state-of-the-art Fourier Neural Operator and traditional classical PDE solvers in its generalization capabilities and performance. This blog post delves into the key contributions of this work, exploring the strategies used to address the common problem of instability in autoregressive models and the design choices of the message passing graph neural network architecture.</p> <p class="post-meta"> 46 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/facial-poisoning/">Data Poisoning is Hitting a Wall</a> </h3> <p>In this post, we look at the paper 'Data Poisoning Won't Save You From Facial Recognition', discuss the impact of the work, and additionally look at how this work fares in the current state of adversarial machine learning. Being a blog post as opposed to a traditional paper, we try to avoid inundating the reader with mathematical equations and complex terminologies. Instead, we aim to put forth this work's primary concept and implications, along with our observations, in a clear, concise manner. Don't want to go through the entire post? Check out the TL;DR at the end for a quick summary.</p> <p class="post-meta"> 17 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/adamw/">Decay No More</a> </h3> <p>Weight decay is among the most important tuning parameters to reach high accuracy for large-scale machine learning models. In this blog post, we revisit AdamW, the weight decay version of Adam, summarizing empirical findings as well as theoretical motivations from an optimization perspective.</p> <p class="post-meta"> 21 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/how-does-the-inductive-bias-influence-the-generalization-capability-of-neural-networks/">How does the inductive bias influence the generalization capability of neural networks?</a> </h3> <p>The blog post discusses how memorization and generalization are affected by extreme overparameterization. Thereforeit explains the overfitting puzzle in machine learning and how the inductive bias can help to understand the generalization capability of neural networks.</p> <p class="post-meta"> 13 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/how-much-meta-learning-is-in-image-to-image-translation/">How much meta-learning is in image-to-image translation?</a> </h3> <p>...in which we find a connection between meta-learning literature and a paper studying how well CNNs deal with nuisance transforms in a class-imbalanced setting. Closer inspection reveals a surprising amount of similarity - from meta-information to loss functions. This implies that the current conception of meta-learning might be too narrow.</p> <p class="post-meta"> 26 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/bsuite-applications/">Practical Applications of Bsuite For Reinforcement Learning</a> </h3> <p>In 2019, researchers at DeepMind published a suite of reinforcement learning environments called Behavior Suite for Reinforcement Learning, or bsuite. Each environment is designed to directly test a core capability of a general reinforcement learning agent, such as its ability to generalize from past experience or handle delayed rewards. In this blog post, we extend their work by providing specific examples of how bsuite can address common challenges faced by reinforcement learning practitioners during the development process.</p> <p class="post-meta"> 37 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/riit/">Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-agent Reinforcement Learning</a> </h3> <p>QMIX, a very classical multi-agent reinforcement learning (MARL) algorithm, is often considered to be a weak performance baseline due to its representation capability limitations. However, we found that by improving the implementation techniques of QMIX we can enable it to achieve state-of-the-art on the StarCraft Multi-Agent Challenge (SMAC) testbed. Furthermore, the key factor of the monotonicity constraint of QMIX was found in this post, we tried to explain its role and corroborated its superior performance by combining it with another actor-critic style algorithm. We have open-sourced the code at https://github.com/hijkzzz/pymarl2 for researchers to evaluate the effects of these proposed techniques.</p> <p class="post-meta"> 39 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/classification-layer-initialization-in-maml/">Strategies for Classification Layer Initialization in Model-Agnostic Meta-Learning</a> </h3> <p>This blog post discusses different strategies for initializing the classification layers parameters before fine-tuning on a new task in Model-Agnostic Meta-Learning. Each of the strategies in question has emerged from a different problemand it will be analyzed whether one approach can solve the problems addressed by the other approaches.</p> <p class="post-meta"> 23 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/raspy/">Thinking Like Transformers</a> </h3> <p>Thinking like Transformers proposes a simple language for coding with attention-like primitives. Using this language, we consider a challenging set of puzzles to gain intuition for how Transformer could implement basic algorithms.</p> <p class="post-meta"> 21 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/2023/blog/2023/sets-and-graphs/">Universality of Neural Networks on Sets vs. Graphs</a> </h3> <p>Universal function approximation is one of the central tenets in theoretical deep learning research. It is the question of whether a specific neural network architecture is, in theory, able to approximate any function of interest. The ICLR paper “How Powerful are Graph Neural Networks?” shows that mathematically analysing the constraints of an architecture as a universal function approximator and alleviating these constraints can lead to more principled architecture choices, performance improvements, and long-term impact on the field. Specifically in the fields of learning on sets and learning on graphs, universal function approximation is a well-studied property. The two fields are closely linked because the need for permutation invariance in both cases leads to similar building blocks. However, we argue that these two fields have sometimes evolved in parallel, not fully exploiting their synergies. This post aims at bringing these two fields closer together, particularly from the perspective of universal function approximation.</p> <p class="post-meta"> 25 min read   ·   May 1, 2023 </p> <p class="post-tags"> <a href="/2023/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> </ul> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/2023/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/2023/assets/js/zoom.js"></script> <script defer src="/2023/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>